{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d61f1c-8dec-4132-9b45-22bd103ff4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "\t.option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"C:/data/retail-data/by-day/2010-12-01.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5b79c5-e680-4cb3-8ae0-e8c4593d837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692cfe25-b8c2-4f0e-8ed8-821fcfcd8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79419b3-6285-4589-9161-b852d18edaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[5: int, five: string, 5.0: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5), lit(\"five\"), lit(5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5f82f9b-fe9a-4c43-b6c2-7da50cb4b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col(\"InvoiceNo\") != 536365).select(\"InvoiceNo\", \"Description\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a1094bb-7c14-479b-8a93-1f860dc8e700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                  |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536366   |22633    |HAND WARMER UNION JACK       |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536366   |22632    |HAND WARMER RED POLKA DOT    |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536367   |84879    |ASSORTED COLOUR BIRD ORNAMENT|32      |2010-12-01 08:34:00|1.69     |13047.0   |United Kingdom|\n",
      "|536367   |22745    |POPPY'S PLAYHOUSE BEDROOM    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "|536367   |22748    |POPPY'S PLAYHOUSE KITCHEN    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"InvoiceNo = 536365\").show(5, False)\n",
    "\n",
    "df.where(\"InvoiceNo <> 536365\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c9491e-10a2-4162-b009-4a9e4f54c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "priceFilter = col(\"UnitPrice\") > 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bacb70a-e9b7-45c3-a879-756d5208dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(UnitPrice > 600)'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priceFilter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3abb7ae3-9539-457a-a9f3-65e769991816",
   "metadata": {},
   "outputs": [],
   "source": [
    "descripFilter = instr(df.Description, \"POSTAGE\") >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fd626b-47c4-4e27-b8b8-402f91f9351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter & descripFilter).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3c4760-7545-4092-8c83-f43ab24b5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow\n",
    "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8b08187-5a05-4fc1-b250-1dcebba737e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95773cc0-211f-4ff6-936b-2560f0db7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         Description|initcap(Description)|\n",
      "+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|White Hanging Hea...|\n",
      "| WHITE METAL LANTERN| White Metal Lantern|\n",
      "|CREAM CUPID HEART...|Cream Cupid Heart...|\n",
      "|KNITTED UNION FLA...|Knitted Union Fla...|\n",
      "|RED WOOLLY HOTTIE...|Red Woolly Hottie...|\n",
      "|SET 7 BABUSHKA NE...|Set 7 Babushka Ne...|\n",
      "|GLASS STAR FROSTE...|Glass Star Froste...|\n",
      "|HAND WARMER UNION...|Hand Warmer Union...|\n",
      "|HAND WARMER RED P...|Hand Warmer Red P...|\n",
      "|ASSORTED COLOUR B...|Assorted Colour B...|\n",
      "|POPPY'S PLAYHOUSE...|Poppy's Playhouse...|\n",
      "|POPPY'S PLAYHOUSE...|Poppy's Playhouse...|\n",
      "|FELTCRAFT PRINCES...|Feltcraft Princes...|\n",
      "|IVORY KNITTED MUG...|Ivory Knitted Mug...|\n",
      "|BOX OF 6 ASSORTED...|Box Of 6 Assorted...|\n",
      "|BOX OF VINTAGE JI...|Box Of Vintage Ji...|\n",
      "|BOX OF VINTAGE AL...|Box Of Vintage Al...|\n",
      "|HOME BUILDING BLO...|Home Building Blo...|\n",
      "|LOVE BUILDING BLO...|Love Building Blo...|\n",
      "|RECIPE BOX WITH M...|Recipe Box With M...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "df.select(col(\"Description\"), initcap(col(\"Description\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "086ef001-0c4f-4bcc-b05c-dfd1c4b789af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, upper\n",
    "df.select(col(\"Description\"), lower(col(\"Description\")), upper(lower(col(\"Description\")))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "772c184b-a44c-4111-9772-0dfa3ee17d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+---+----------+\n",
      "|  ltrim|  rtrim| trim| lp|        rp|\n",
      "+-------+-------+-----+---+----------+\n",
      "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
      "+-------+-------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "ltrim(lit(\"  HELLO  \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\"  HELLO  \")).alias(\"rtrim\"),\n",
    "trim(lit(\"  HELLO  \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23b4f77d-f7aa-4443-a32d-c41ed017a86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = spark.range(10)\\\n",
    "\t.withColumn(\"today\", current_date())\\\n",
    "\t.withColumn(\"now\", current_timestamp())\n",
    "\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")\n",
    "\n",
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c87de13-4d5a-45b2-96e2-a42b4ff3cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|     today|                 now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2024-06-20|2024-06-20 22:19:...|\n",
      "|  1|2024-06-20|2024-06-20 22:19:...|\n",
      "|  2|2024-06-20|2024-06-20 22:19:...|\n",
      "|  3|2024-06-20|2024-06-20 22:19:...|\n",
      "|  4|2024-06-20|2024-06-20 22:19:...|\n",
      "|  5|2024-06-20|2024-06-20 22:19:...|\n",
      "|  6|2024-06-20|2024-06-20 22:19:...|\n",
      "|  7|2024-06-20|2024-06-20 22:19:...|\n",
      "|  8|2024-06-20|2024-06-20 22:19:...|\n",
      "|  9|2024-06-20|2024-06-20 22:19:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8771d1d4-96aa-491c-8cfa-e2482d6d5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2024-06-15|        2024-06-25|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub\n",
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c14148f8-6174-4bd6-8129-80a22e0bc5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    "\t.select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecfe38c-6b63-4958-8d88-8470e9b4cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(\n",
    "      to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "      to_date(lit(\"2017-05-22\")).alias(\"end\"))\\\n",
    "      .select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cd90035-abe8-4fb9-a573-3edd58c5b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|to_date(2016-20-12)|to_date(2017-12-11)|\n",
      "+-------------------+-------------------+\n",
      "|               NULL|         2017-12-11|\n",
      "+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(to_date(lit(\"2016-20-12\")),to_date(lit(\"2017-12-11\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36147d8-0d16-4074-987b-40baf7ace3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "\n",
    "dateFormat = \"yyyy-dd-MM\"\n",
    "\n",
    "cleanDateDF = spark.range(1).select(\n",
    "  to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
    "  to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\"))\n",
    "cleanDateDF.createOrReplaceTempView(\"dateTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3401e98-e7b5-493c-9a87-dbc4b7e039cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2017-11-12|2017-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanDateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55e79b7a-dc00-4e56-ac57-508c650280af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5a2de7-2453-4b87-8952-03c330a49657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             complex|\n",
      "+--------------------+\n",
      "|{WHITE HANGING HE...|\n",
      "|{WHITE METAL LANT...|\n",
      "|{CREAM CUPID HEAR...|\n",
      "|{KNITTED UNION FL...|\n",
      "|{RED WOOLLY HOTTI...|\n",
      "|{SET 7 BABUSHKA N...|\n",
      "|{GLASS STAR FROST...|\n",
      "|{HAND WARMER UNIO...|\n",
      "|{HAND WARMER RED ...|\n",
      "|{ASSORTED COLOUR ...|\n",
      "|{POPPY'S PLAYHOUS...|\n",
      "|{POPPY'S PLAYHOUS...|\n",
      "|{FELTCRAFT PRINCE...|\n",
      "|{IVORY KNITTED MU...|\n",
      "|{BOX OF 6 ASSORTE...|\n",
      "|{BOX OF VINTAGE J...|\n",
      "|{BOX OF VINTAGE A...|\n",
      "|{HOME BUILDING BL...|\n",
      "|{LOVE BUILDING BL...|\n",
      "|{RECIPE BOX WITH ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23a42913-71de-4ba9-a079-a313925363fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|InvoiceNo|\n",
      "+---------+\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536366|\n",
      "|   536366|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.InvoiceNo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b85ef640-d83f-4441-ab58-a11d7de4e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| complex.Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|\n",
      "|KNITTED UNION FLA...|\n",
      "|RED WOOLLY HOTTIE...|\n",
      "|SET 7 BABUSHKA NE...|\n",
      "|GLASS STAR FROSTE...|\n",
      "|HAND WARMER UNION...|\n",
      "|HAND WARMER RED P...|\n",
      "|ASSORTED COLOUR B...|\n",
      "|POPPY'S PLAYHOUSE...|\n",
      "|POPPY'S PLAYHOUSE...|\n",
      "|FELTCRAFT PRINCES...|\n",
      "|IVORY KNITTED MUG...|\n",
      "|BOX OF 6 ASSORTED...|\n",
      "|BOX OF VINTAGE JI...|\n",
      "|BOX OF VINTAGE AL...|\n",
      "|HOME BUILDING BLO...|\n",
      "|LOVE BUILDING BLO...|\n",
      "|RECIPE BOX WITH M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(col(\"complex\").getField(\"Description\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3889e3d4-be98-48e2-a56b-dd69dafc1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [WHITE, HANGING, ...|\n",
      "|     [WHITE, METAL, LA...|\n",
      "|     [CREAM, CUPID, HE...|\n",
      "|     [KNITTED, UNION, ...|\n",
      "|     [RED, WOOLLY, HOT...|\n",
      "|     [SET, 7, BABUSHKA...|\n",
      "|     [GLASS, STAR, FRO...|\n",
      "|     [HAND, WARMER, UN...|\n",
      "|     [HAND, WARMER, RE...|\n",
      "|     [ASSORTED, COLOUR...|\n",
      "|     [POPPY'S, PLAYHOU...|\n",
      "|     [POPPY'S, PLAYHOU...|\n",
      "|     [FELTCRAFT, PRINC...|\n",
      "|     [IVORY, KNITTED, ...|\n",
      "|     [BOX, OF, 6, ASSO...|\n",
      "|     [BOX, OF, VINTAGE...|\n",
      "|     [BOX, OF, VINTAGE...|\n",
      "|     [HOME, BUILDING, ...|\n",
      "|     [LOVE, BUILDING, ...|\n",
      "|     [RECIPE, BOX, WIT...|\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "\n",
    "df.select(split(col(\"Description\"), \" \")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c72193e6-70eb-494b-b4b0-0d1c5c64d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|array_col[0]|array_col[1]|\n",
      "+------------+------------+\n",
      "|       WHITE|     HANGING|\n",
      "|       WHITE|       METAL|\n",
      "|       CREAM|       CUPID|\n",
      "|     KNITTED|       UNION|\n",
      "|         RED|      WOOLLY|\n",
      "|         SET|           7|\n",
      "|       GLASS|        STAR|\n",
      "|        HAND|      WARMER|\n",
      "|        HAND|      WARMER|\n",
      "|    ASSORTED|      COLOUR|\n",
      "|     POPPY'S|   PLAYHOUSE|\n",
      "|     POPPY'S|   PLAYHOUSE|\n",
      "|   FELTCRAFT|    PRINCESS|\n",
      "|       IVORY|     KNITTED|\n",
      "|         BOX|          OF|\n",
      "|         BOX|          OF|\n",
      "|         BOX|          OF|\n",
      "|        HOME|    BUILDING|\n",
      "|        LOVE|    BUILDING|\n",
      "|      RECIPE|         BOX|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\")).selectExpr(\"array_col[0]\",\"array_col[1]\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ff01138-c922-4871-95ca-7bd179af142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+\n",
      "|         Description|InvoiceNo|exploded|\n",
      "+--------------------+---------+--------+\n",
      "|WHITE HANGING HEA...|   536365|   WHITE|\n",
      "|WHITE HANGING HEA...|   536365| HANGING|\n",
      "+--------------------+---------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    "\t.withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    "    .select(\"Description\", \"InvoiceNo\", \"exploded\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bc596a5-c52e-49eb-a042-907def979534",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDF = spark.range(1).selectExpr(\"\"\"'{\"myJSONKey\" : {\"myJSONValue\" : [1, 2, 3]}}' as jsonString\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6992f8db-9fc5-41e8-bb02-3b83faf8843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          jsonString|\n",
      "+--------------------+\n",
      "|{\"myJSONKey\" : {\"...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba1151ca-7fd8-4202-a74a-25b99300107d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udfExampleDF = spark.range(5).toDF(\"num\")\n",
    "\n",
    "def power3(double_value):\n",
    "    return double_value ** 3\n",
    "\n",
    "power3(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b63cacc5-35cf-4b71-ae47-127a335e9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "power3udf = udf(power3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3415e-d625-4717-991f-26140aa13924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
